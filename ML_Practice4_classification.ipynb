{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfANgwbjxcnsoDnv/SDz5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjhan1201/AIFFEL_Online_Quest/blob/main/ML_Practice4_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKkx7ZSGcnC4",
        "outputId": "8ce8f264-5b23-4d50-d8c1-c5ac2c42335d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9983232729711603"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#의사결정나무\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "#데이터 생성\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "def make_dataset():\n",
        "  iris = load_breast_cancer()\n",
        "  df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "  df['target'] = iris.target\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      df.drop('target',axis=1), df['target'],test_size=0.5,random_state=1004)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = make_dataset()\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "#타겟확인\n",
        "y_train.value_counts()\n",
        "#의사결정나무\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test,pred)\n",
        "#의사결정나무하이퍼 파라미터 설정\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion = 'entropy',\n",
        "    max_depth =6 ,\n",
        "    min_samples_leaf = 2,\n",
        "    min_samples_split = 3,\n",
        "    random_state = 0)\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test,pred)\n",
        "\n",
        "#랜덤포레스트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "\n",
        "#xgboost\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
        "                      booster = 'gbtree',\n",
        "                      objective = 'binary:logistic',\n",
        "                      max_depth = 5,\n",
        "                      learning_rate = 0.05,\n",
        "                      n_estimators = 500,\n",
        "                      subsample = 1,\n",
        "                      colsample_bytree = 1,\n",
        "                      n_jobs = -1\n",
        ")\n",
        "\n",
        "# xgboost 하이퍼파라미터\n",
        "# - booster(기본값 gbtree): 부스팅 알고리즘 (또는 dart, gblinear)\n",
        "# - objective(기본값 binary:logistic): 이진분류 (다중분류: multi:softmax)\n",
        "# - max_depth(기본값 6): 최대 한도 깊이\n",
        "# - learning_rate(기본값 0.1): 학습률\n",
        "# - n_estimators(기본값 100): 트리의 수\n",
        "# - subsample(기본값 1): 훈련 샘플 개수의 비율\n",
        "# - colsample_bytree(기본값 1): 특성 개수의 비율\n",
        "# - n_jobs(기본값 1): 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
        "\n",
        "#조기종료\n",
        "# model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
        "#                       booster = 'gbtree',\n",
        "#                       objective = 'binary:logistic',\n",
        "#                       max_depth = 5,\n",
        "#                       learning_rate = 0.05,\n",
        "#                       n_estimators = 500,\n",
        "#                       subsample = 1,\n",
        "#                       colsample_bytree = 1,\n",
        "#                       n_jobs = -1\n",
        "# )\n",
        "# eval_set = [(X_test,y_test)]\n",
        "# model.fit(X_train, y_train,eval_set = eval_set, early_stopping_rounds = 10)\n",
        "# pred = model.predict(X_test)\n",
        "# accuracy_score(y_test, pred)\n",
        "\n",
        "##교차검증\n",
        "# 데이터셋 로드\n",
        "def make_dataset2():\n",
        "    bc = load_breast_cancer()\n",
        "    df = pd.DataFrame(bc.data, columns=bc.feature_names)\n",
        "    df['target'] = bc.target\n",
        "    return df.drop('target', axis=1), df['target']\n",
        "X, y = make_dataset2()\n",
        "\n",
        "#Kfold\n",
        "from sklearn.model_selection import KFold\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "for train_idx, test_idx in kfold.split(X):\n",
        "  X_train, X_test = X.iloc[train_idx],X.iloc[test_idx]\n",
        "  y_train, y_test = y.iloc[train_idx],y.iloc[test_idx]\n",
        "  model.fit(X_train, y_train)\n",
        "  pred = model.predict(X_test)\n",
        "  # print(accuracy_score(y_test, pred))\n",
        "\n",
        "#StratifiedKfold 불균형한 타겟비율을 가진 데이터가 한쪽으로 치우치는것을 방지\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5)\n",
        "for train_idx, test_idx in kfold.split(X,y):\n",
        "  X_train, X_test = X.iloc[train_idx],X.iloc[test_idx]\n",
        "  y_train, y_test = y.iloc[train_idx],y.iloc[test_idx]\n",
        "  model.fit(X_train, y_train)\n",
        "  pred = model.predict(X_test)\n",
        "  # print(accuracy_score(y_test, pred))\n",
        "\n",
        "#사이킷런 교차검증\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(model,X,y,cv=3)\n",
        "scores.mean()\n",
        "#사이킷런 교차검증 - StratifiedKfold 적용\n",
        "kfold = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model,X,y,cv=kfold)\n",
        "scores.mean()\n",
        "\n",
        "#분류모델의 평가\n",
        "#정확도\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,pred)\n",
        "#정밀도\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_test,pred)\n",
        "#재현율\n",
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test,pred)\n",
        "#f1\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test,pred)\n",
        "#roc_auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict_proba(X_test)\n",
        "roc_auc_score(y_test, pred[:,1])"
      ]
    }
  ]
}