{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq2zyyV2vJ3l7BLf41QSwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjhan1201/AIFFEL_Online_Quest/blob/main/ML_Practice4_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKkx7ZSGcnC4",
        "outputId": "7104e102-668a-4bc8-bfdb-683333e67a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8771929824561403\n",
            "0.9122807017543859\n",
            "0.9473684210526315\n",
            "0.9385964912280702\n",
            "0.8407079646017699\n"
          ]
        }
      ],
      "source": [
        "#의사결정나무\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "#데이터 생성\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "def make_dataset():\n",
        "  iris = load_breast_cancer()\n",
        "  df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "  df['target'] = iris.target\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      df.drop('target',axis=1), df['target'],test_size=0.5,random_state=1004)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = make_dataset()\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "#타겟확인\n",
        "y_train.value_counts()\n",
        "#의사결정나무\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test,pred)\n",
        "#의사결정나무하이퍼 파라미터 설정\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion = 'entropy',\n",
        "    max_depth =6 ,\n",
        "    min_samples_leaf = 2,\n",
        "    min_samples_split = 3,\n",
        "    random_state = 0)\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test,pred)\n",
        "\n",
        "#랜덤포레스트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "\n",
        "#xgboost\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
        "                      booster = 'gbtree',\n",
        "                      objective = 'binary:logistic',\n",
        "                      max_depth = 5,\n",
        "                      learning_rate = 0.05,\n",
        "                      n_estimators = 500,\n",
        "                      subsample = 1,\n",
        "                      colsample_bytree = 1,\n",
        "                      n_jobs = -1\n",
        ")\n",
        "\n",
        "# xgboost 하이퍼파라미터\n",
        "# - booster(기본값 gbtree): 부스팅 알고리즘 (또는 dart, gblinear)\n",
        "# - objective(기본값 binary:logistic): 이진분류 (다중분류: multi:softmax)\n",
        "# - max_depth(기본값 6): 최대 한도 깊이\n",
        "# - learning_rate(기본값 0.1): 학습률\n",
        "# - n_estimators(기본값 100): 트리의 수\n",
        "# - subsample(기본값 1): 훈련 샘플 개수의 비율\n",
        "# - colsample_bytree(기본값 1): 특성 개수의 비율\n",
        "# - n_jobs(기본값 1): 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "#조기종료\n",
        "# model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
        "#                       booster = 'gbtree',\n",
        "#                       objective = 'binary:logistic',\n",
        "#                       max_depth = 5,\n",
        "#                       learning_rate = 0.05,\n",
        "#                       n_estimators = 500,\n",
        "#                       subsample = 1,\n",
        "#                       colsample_bytree = 1,\n",
        "#                       n_jobs = -1\n",
        "# )\n",
        "# eval_set = [(X_test,y_test)]\n",
        "# model.fit(X_train, y_train,eval_set = eval_set, early_stopping_rounds = 10)\n",
        "# pred = model.predict(X_test)\n",
        "# accuracy_score(y_test, pred)\n",
        "\n",
        "#교차검증\n",
        "# 데이터셋 로드\n",
        "def make_dataset2():\n",
        "    bc = load_breast_cancer()\n",
        "    df = pd.DataFrame(bc.data, columns=bc.feature_names)\n",
        "    df['target'] = bc.target\n",
        "    return df.drop('target', axis=1), df['target']\n",
        "X, y = make_dataset2()\n",
        "\n",
        "#Kfold\n",
        "from sklearn.model_selection import KFold\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "for train_idx, test_idx in kfold.split(X):\n",
        "  X_train, X_test = X.iloc[train_idx],X.iloc[test_idx]\n",
        "  y_train, y_test = y.iloc[train_idx],y.iloc[test_idx]\n",
        "  model.fit(X_train, y_train)\n",
        "  pred = model.predict(X_test)\n",
        "  print(accuracy_score(y_test, pred))\n",
        "\n",
        "#StratifiedKfold\n",
        "\n"
      ]
    }
  ]
}