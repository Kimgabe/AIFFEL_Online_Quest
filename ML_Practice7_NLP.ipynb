{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmWWCfwDNS3bkXQydC98wB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjhan1201/AIFFEL_Online_Quest/blob/main/ML_Practice7_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9mjyqQpyE3y",
        "outputId": "dcbee30a-630e-4921-f54b-1a5503cde1f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'함께': 4, '탐험': 2, '성장하는': 1, '학교': 3, 'aiffel': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#자연어 처리 기초\n",
        "#형태소 분석기\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip install konlpy\n",
        "#라이브러리\n",
        "import konlpy\n",
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt()\n",
        "#토큰화\n",
        "text = \"함께 탐험하며 성장하는 AI 학교 AIFFEL\"\n",
        "tokenizer.morphs(text)\n",
        "tokenizer.nouns(text) #명사만\n",
        "tokenizer.pos(text)  #품사 태깅\n",
        "\n",
        "#CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()\n",
        "#단어 토큰화(Okt)\n",
        "words = tokenizer.morphs(text)\n",
        "#데이터학습\n",
        "vect.fit(words)\n",
        "#학습된 어휘\n",
        "vect.get_feature_names_out()\n",
        "#단어사전\n",
        "vect.vocabulary_\n",
        "#단어사전 크기\n",
        "len(vect.vocabulary_)\n",
        "#인코딩\n",
        "df_t = vect.transform(words)\n",
        "df_t.toarray()\n",
        "#어휘와 피처\n",
        "pd.DataFrame(df_t.toarray(), columns=vect.get_feature_names_out())\n",
        "#TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer()\n",
        "words = tokenizer.morphs(text)\n",
        "vect.fit(words)\n",
        "vect.vocabulary_\n",
        "vect.transform(words).toarray()\n",
        "\n",
        "#감성분석\n",
        "# import pandas as pd\n",
        "# #데이터 로드\n",
        "# df = pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", sep=\"\\t\")\n",
        "# #타겟 확인\n",
        "# df['label'].value_counts()\n",
        "# #결측치 확인\n",
        "# df.isnull().sum()\n",
        "# #결측치 삭제\n",
        "# df.shape\n",
        "# df = df.dropna()\n",
        "# df.shape\n",
        "\n",
        "# #피처 엔지니어링(문장의 길이)\n",
        "# df['len'] = df['document'].apply(len)\n",
        "# #len 시각화\n",
        "# import matplotlib.pyplot as plt\n",
        "# df[df.label == 0]['len'].plot(kind='hist')\n",
        "# df[df.label == 1]['len'].plot(kind='hist')\n",
        "# #데이터 샘플링\n",
        "# df = df[:1000]\n",
        "# #토큰화\n",
        "# vect = CountVectorizer(tokenizer=tokenizer.morphs)\n",
        "# vectors = vect.fit_transform(df['document'])\n",
        "# #머신러닝 교차 검증\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# model = RandomForestClassifier(random_state=2022)\n",
        "# cross_val_score(model, vectors, df['label'], scoring='f1', cv=5).mean()\n",
        "\n",
        "#자연어 전처리\n",
        "#사전 만들기\n",
        "vect = CountVectorizer(tokenizer=tokenizer.morphs, max_df=10)\n",
        "vectors = vect.fit_transform(df['document'])\n",
        "model = RandomForestClassifier(random_state=2022)\n",
        "cross_val_score(model, vectors, df['label'], scoring='accuracy', cv=5).mean()\n",
        "#불용어\n",
        "text = \"함께 탐험하며 성장하는 AI 학교 AIFFEL\"\n",
        "stop_words = ['하며','ai']\n",
        "vect = CountVectorizer(stop_words = stop_words)\n",
        "words = tokenizer.morphs(text)\n",
        "vect.fit(words)\n",
        "vect.vocabulary_"
      ]
    }
  ]
}