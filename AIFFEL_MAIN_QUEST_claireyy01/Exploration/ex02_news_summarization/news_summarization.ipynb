{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3ab369",
   "metadata": {},
   "source": [
    "# 뉴스 요약본 만들기\n",
    "## 개요\n",
    "\n",
    "## 목차\n",
    "1. 데이터 준비하기\n",
    "- NLTK(라이브러리)와 NLTK 불용어 사전 다운로드\n",
    "- 데이터 전처리를 위한 패키지 다운로드\n",
    "- 데이터 샘플을 불러와 확인하기\n",
    "- 데이터프레임에서 훈련에 사용할 Text, Summary 열만 남기기 \n",
    "\n",
    "2. 데이터 전처리하기 - (1) 데이터 정리하기\n",
    "- 중복 샘플 제거하기 - 데이터프레임의 drop_duplicates()를 사용\n",
    "- 데이터프레임에 Null 값이 있는지 확인 및 제거 - .isnull().sum()함수와 dropna()함수 사용\n",
    "- 텍스트 정규화\n",
    "- 불용어 처리\n",
    "\n",
    "3. 데이터 전처리하기 - (2) 훈련데이터와 테스트데이터 나누기\n",
    "4. 데이터 전처리하기 - (3) 정수 인코딩\n",
    "5. 모델 설계하기\n",
    "6. 모델 훈련하기\n",
    "7. 인퍼런스 모델 구현하기\n",
    "8. 모델 테스트하기\n",
    "9. 추출적 요약 해보기\n",
    "\n",
    "## 회고\n",
    "\n",
    "## Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4858ede",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기\n",
    "NLTK의 불용어(stopwords)를 사용합니다.  \n",
    "- NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리입니다.  \n",
    "- 이 NLTK에는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장하지만,   \n",
    "의미를 분석하고 요약하는 데는 거의 의미가 없는 100여개의 불용어가 미리 정리되어 있습니다.\n",
    "- 이를 이용해 다운로드한 리뷰 파일에서 불용어를 제거하는 작업을 진행합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8009a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# NLTK 설치\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282d417",
   "metadata": {},
   "source": [
    "경고 메세지  \n",
    "일반적으로 사용자가 시스템 루트 권한으로 pip를 실행했을 때 나타납니다.   \n",
    "시스템 루트 권한으로 pip를 실행하면 시스템 전체에 대한 패키지 설치가 이루어지며,   \n",
    "이는 시스템 라이브러리와 충돌하거나 권한 문제를 일으킬 수 있다는 경고 메세지입니다.  \n",
    "터미널에서 가상 환경을 사용하여 패키지를 설치하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ad914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 가상환경 생성\n",
    "# python -m venv myenv\n",
    "\n",
    "# # 가상환경 활성화\n",
    "# source myenv/bin/activate\n",
    "\n",
    "# # 가상환경에서 패키지 설치\n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a281317",
   "metadata": {},
   "source": [
    "NLTK 패키지에서 불용어 사전을 다운로드하고, 데이터 전처리를 위한 나머지 패키지도 함께 불러와 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956ac71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re   # 정규 표현식을 사용하기 위한 re (Regular Expression) 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords   # nltk에서 제공하는 불용어 데이터를 사용하기 위해 stopwords를 가져오기\n",
    "from bs4 import BeautifulSoup       # HTML 또는 XML과 같은 마크업 언어에서 데이터를 추출하기 위한 BeautifulSoup 라이브러리를 가져오기\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer: 텍스트를 토큰화하기 위한 Keras의 Tokenizer를 가져옵니다.\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences: \n",
    "# 시퀀스 데이터를 패딩하기 위한 Keras의 pad_sequences를 가져옵니다.\n",
    "# import urllib.request: 웹에서 데이터를 다운로드하기 위한 urllib 라이브러리를 가져옵니다.\n",
    "# import warnings: 경고 메시지를 처리하기 위한 warnings 모듈을 가져옵니다.\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4'): \n",
    "# BeautifulSoup 모듈에서 발생하는 UserWarning을 무시하도록 경고 메시지를 필터링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f3c31",
   "metadata": {},
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 갖고 있습니다.  \n",
    "시간 상 여기서는 모든 샘플을 사용하지는 않고, 간단히 10만 개의 샘플만 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61909be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b23989",
   "metadata": {},
   "source": [
    "출력된 샘플 수를 보면 총 10만 개의 샘플이 잘 불러와진 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102bdfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 5개만 출력해보기\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cc143",
   "metadata": {},
   "source": [
    "전체 데이터 중 Summary 열과 Text 열만 훈련에 사용할 거라, 이 두 개의 열만 별도로 저장하고, 다시 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ac57db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70339</th>\n",
       "      <td>There's only one thing keeping me from giving ...</td>\n",
       "      <td>Not bad, has a bit of a weird aftertaste, though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26428</th>\n",
       "      <td>The product is not fresh when they send it bec...</td>\n",
       "      <td>not sealed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16443</th>\n",
       "      <td>I have enjoyed this brand of coffee for severa...</td>\n",
       "      <td>awesome coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55588</th>\n",
       "      <td>I enjoy cereal and this cereal is like most su...</td>\n",
       "      <td>TASTY, BUT NOTHING NEW!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87907</th>\n",
       "      <td>This product is very helpful in training my do...</td>\n",
       "      <td>Handy and WORKS!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42879</th>\n",
       "      <td>When the bar of NEWMAN'S OWN ORGANICS DARK CHO...</td>\n",
       "      <td>Don't Be Afraid Of The Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24805</th>\n",
       "      <td>My dog doesn't like big bones. She barely chew...</td>\n",
       "      <td>USA &amp; Size Matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75248</th>\n",
       "      <td>I have 2 small dogs, that absolutely love gree...</td>\n",
       "      <td>amazing value price.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62239</th>\n",
       "      <td>The strong, spicy aroma (clove and cinnamon do...</td>\n",
       "      <td>Powerful stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13038</th>\n",
       "      <td>I first ate these in Ireland. This pub I went ...</td>\n",
       "      <td>MY ABSOLUTE FAVORITE COOKIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38697</th>\n",
       "      <td>Juicy Juice is always a hit in our family and ...</td>\n",
       "      <td>Who doesn't love Juicy Juice?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>I expected more flavor from W. Puck. Though th...</td>\n",
       "      <td>Good, not Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62343</th>\n",
       "      <td>If you enjoy Earl Grey tea, once you try \"doub...</td>\n",
       "      <td>Stash brand teas: A personal favorite for 10+ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74974</th>\n",
       "      <td>My three dogs love Greenies.  So much so that ...</td>\n",
       "      <td>My Dogs LOVE Greenies!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52406</th>\n",
       "      <td>This is a great snack, low calorie, tasty, and...</td>\n",
       "      <td>Very tasty, healthy snack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "70339  There's only one thing keeping me from giving ...   \n",
       "26428  The product is not fresh when they send it bec...   \n",
       "16443  I have enjoyed this brand of coffee for severa...   \n",
       "55588  I enjoy cereal and this cereal is like most su...   \n",
       "87907  This product is very helpful in training my do...   \n",
       "42879  When the bar of NEWMAN'S OWN ORGANICS DARK CHO...   \n",
       "24805  My dog doesn't like big bones. She barely chew...   \n",
       "75248  I have 2 small dogs, that absolutely love gree...   \n",
       "62239  The strong, spicy aroma (clove and cinnamon do...   \n",
       "13038  I first ate these in Ireland. This pub I went ...   \n",
       "38697  Juicy Juice is always a hit in our family and ...   \n",
       "9158   I expected more flavor from W. Puck. Though th...   \n",
       "62343  If you enjoy Earl Grey tea, once you try \"doub...   \n",
       "74974  My three dogs love Greenies.  So much so that ...   \n",
       "52406  This is a great snack, low calorie, tasty, and...   \n",
       "\n",
       "                                                 Summary  \n",
       "70339   Not bad, has a bit of a weird aftertaste, though  \n",
       "26428                                         not sealed  \n",
       "16443                                     awesome coffee  \n",
       "55588                            TASTY, BUT NOTHING NEW!  \n",
       "87907                                   Handy and WORKS!  \n",
       "42879                        Don't Be Afraid Of The Dark  \n",
       "24805                                 USA & Size Matters  \n",
       "75248                               amazing value price.  \n",
       "62239                                     Powerful stuff  \n",
       "13038                        MY ABSOLUTE FAVORITE COOKIE  \n",
       "38697                      Who doesn't love Juicy Juice?  \n",
       "9158                                     Good, not Great  \n",
       "62343  Stash brand teas: A personal favorite for 10+ ...  \n",
       "74974                             My Dogs LOVE Greenies!  \n",
       "52406                          Very tasty, healthy snack  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 데이터프레임 data의 Text와 Summary 컬럼의 데이터만 남기는 코드를 작성하세요.\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "selected_columns = ['Text', 'Summary']\n",
    "data = data[selected_columns]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d8953",
   "metadata": {},
   "source": [
    "Text 열의 내용을 요약한 것이 Summary 열입니다.  \n",
    "여기서는 인공 신경망을 통해 Text 시퀀스를 입력받으면, Summary 시퀀스를 예측하도록 인공 신경망을 훈련시켜보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d098c2",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리하기 - (1) 데이터 정리하기\n",
    "빈칸으로 존재하는 null 데이터, 의미는 같지만 다른 식으로 작성된 글 같은 중복 항목과 같은 학습할 때 방해가 되는 데이터를 먼저 솎아내겠습니다.  \n",
    "\n",
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18aa857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 중복 샘플 유무를 확인하기\n",
    "\n",
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e7f89",
   "metadata": {},
   "source": [
    "> 해석  \n",
    "> - 중복을 제외한다면 Text에는 88,426개, Summary에는 72,348개의 유니크한 데이터가 존재\n",
    "> - 이 데이터의 Summary는 'Smelly'나 'Good Product'와 같이 아주 간단한 요약들도 많아서 Text가 달라도 Summary는 동일할 수 있음.\n",
    "> - 하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9571b8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# 중복 샘플 제거하기 - 데이터프레임의 drop_duplicates()를 사용\n",
    "\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))\n",
    "\n",
    "# subset은 중복을 검사할 때 어떤 컬럼 또는 컬럼의 집합을 기준으로 할지를 지정하는 매개변수\n",
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6fe68",
   "metadata": {},
   "source": [
    "> 중복이 제거되면서 샘플 수가 88,426개로 줄어들었습니다.  \n",
    "drop_duplicates() 함수는 중복된 Null들을 완전히 삭제하지는 못할 수 있으므로 데이터에 Null 값이 남아있는지 확인해야 합니다.  \n",
    "(만약 데이터 Null 값을 가지는 샘플이 있었다면,   \n",
    "drop_duplicates()가 중복된 Null들을 지워주기는 하겠지만, 여전히 Null 값 한 개가 어딘가 남아있을 수 있습니다.)       \n",
    "데이터에 Null 값이 남아있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e720ed57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임에 Null 값이 있는지 확인 - .isnull().sum()을 사용\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7d5d4",
   "metadata": {},
   "source": [
    "Summary에 1개의 Null 값이 있습니다. Null을 제거하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "996c3f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임에서 Null을 제거하기 - dropna() 함수를 사용하면 돼요.\n",
    "\n",
    "data.dropna(axis=0, inplace=True)   # axis=0는 행(row)을 기준으로 NaN 값이 있는 행을 제거하도록 지정\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e285774",
   "metadata": {},
   "source": [
    "> 전체 샘플 수가 1개 줄어들어 88,425개의 샘플이 남았습니다.  \n",
    "지금까지 중복 샘플과 Null 값이 있는 샘플들을 제거해보았는데 10만 개의 샘플 중 1만 개 이상의 샘플이 제거되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b110155",
   "metadata": {},
   "source": [
    "## 텍스트 정규화와 불용어 제거\n",
    "### 텍스트 정규화 : 동의어를 1개의 표현으로 통일시켜주어 기계의 연산량을 줄이기\n",
    "\n",
    "살아남은 88,425개의 샘플에는 수많은 단어들이 있습니다.  \n",
    "그런데 사실 그 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있습니다.  \n",
    "\n",
    "예를 들어서 it'll은 it will과 같고, mustn't과 must not은 사실 같은 표현입니다.  \n",
    "이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는   \n",
    "기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법입니다.  \n",
    "\n",
    "이러한 방법론을 텍스트 처리에서는 **텍스트 정규화(text normalization)** 라고 합니다.   \n",
    "\n",
    "여기서는 텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성합니다.  \n",
    "이 사전은 아래의 링크에서 참고하여 만들었습니다.  \n",
    "[정규화 사전 출처](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "807f1da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화를 위한 사전 구성\n",
    "\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80988f52",
   "metadata": {},
   "source": [
    "### 불용어 처리\n",
    "\n",
    "**일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재**합니다.  \n",
    "이를 **불용어(stopwords)**라고 부릅니다. 때로는 불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있습니다.  \n",
    "여기서는 NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82dd7d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 개수와 불용어 확인하기\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650dff8",
   "metadata": {},
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개라는 것을 볼 수 있습니다. 이를 사용하여 불용어를 제거하겠습니다.   \n",
    "\n",
    "**최종적인 불용어 제거 작업**은 아래와 같습니다.  \n",
    "- NLTK에서 미리 정의하여 제공하고 있는 불용어 제거\n",
    "- 모든 영어 문자는 소문자로 만들기\n",
    "- 섞여있는 html 태그를 제거\n",
    "- 정규 표현식을 통해 각종 특수문자를 제거  \n",
    "\n",
    "위의 작업으로 정말 필요한 내용만 잘 학습할 수 있도록 처리하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed42cee",
   "metadata": {},
   "source": [
    "**NLTK를 이용해 불용어를 제거하는 파트**  \n",
    "- Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 Summary 전처리할 때는 호출하지 않을 것\n",
    "- Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는 게 더 좋음\n",
    "- 이 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a53f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')\n",
    "\n",
    "# sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) \n",
    "# 텍스트 내의 약어를 정규화하는 과정을 수행\n",
    "# contractions는 축약형을 키(key)로 가지고, 해당 축약형을 전체 단어로 대체할 값을 값(value)으로 가지는 딕셔너리\n",
    "# 예를 들어, \"I'm\"은 \"I am\"으로 변환되고, \"won't\"은 \"will not\"으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06c62ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 임의의 text와 summary를 만들어 함수를 호출해보기 (함수가 잘 만들어졌는지 확인)\n",
    "\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dad8aa",
   "metadata": {},
   "source": [
    "> 결과 해석   \n",
    "> - 기본적으로 모든 알파벳이 소문자로 변환되고, <br />과 같은 html 태그가 제거되었습니다.\n",
    "> - (or finish)와 같은 괄호로 묶였던 단어 시퀀스가 제거되었으며, 특수문자가 제거되면서 영어만 남았습니다.  \n",
    "\n",
    "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행합니다.  \n",
    "이때, **Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행**해야 합니다.  \n",
    "먼저 Text를 전처리하고, 결과를 확인하기 위해서 상위 5개의 줄을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ed9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다.\n",
    "clean_text = []\n",
    "\n",
    "# 판다스 데이터프레임의 행(row)을 순회하는 함수 iterrows()를 활용\n",
    "for i, row in data.iterrows():\n",
    "    # \"Text\" 컬럼에 대한 전처리\n",
    "    preprocessed_text = preprocess_sentence(row['Text'], remove_stopwords=True)\n",
    "    \n",
    "    # 결과를 clean_text 리스트에 추가\n",
    "    clean_text.append(preprocessed_text)\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481e9dd",
   "metadata": {},
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출해 줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cbf3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Summary 데이터에 대한 전처리 \n",
    "clean_summary = []\n",
    "\n",
    "# 판다스 데이터프레임의 행(row)을 순회하는 함수 iterrows()를 활용\n",
    "for i, row in data.iterrows():\n",
    "    # \"Summary\" 컬럼에 대한 전처리\n",
    "    preprocessed_summary = preprocess_sentence(row['Summary'], remove_stopwords=False)\n",
    "\n",
    "    # 결과를 clean_summary 리스트에 추가\n",
    "    clean_summary.append(preprocessed_summary)\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1ba4e",
   "metadata": {},
   "source": [
    "**텍스트 정제 과정을 거친 후에는 빈(empty) 샘플이 생겼는지 다시 한 번 확인해보기!!**  \n",
    "\n",
    "> Why?  정제 과정에서 문장의 모든 단어가 사라지는 경우(=샘플 자체가 빈 값이 되는 경우)가 생겼는지 확인하기 위해!    \n",
    ">\n",
    "> 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있습니다.  \n",
    "> 이렇게 되면 샘플 자체가 빈 값을 가지게 되므로\n",
    "\n",
    "**데이터들을 데이터프레임에 재저장하기**\n",
    "- 보다 쉽게 확인하기 위해  \n",
    "- 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef421ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc1de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null 값이 생겼는지 확인 - .isnull().sum()을 사용하여\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd6ceb",
   "metadata": {},
   "source": [
    "Summary 열에서 70개의 Null 값이 생겼습니다.  \n",
    "원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미입니다.   \n",
    "이 샘플들은 모두 제거해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9203acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "# 정제 과정 후 생긴 빈 샘플을 모두 제거하기 \n",
    "\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441aac32",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리하기 - (2) 훈련데이터와 테스트데이터 나누기\n",
    "학습을 진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고, 문장의 시작과 끝을 표시해 주어야 합니다.  \n",
    "\n",
    "### 샘플의 최대 길이 정하기\n",
    "필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례입니다.  \n",
    "Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78e2d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "# bins는 히스토그램에서 데이터를 나누는 구간의 개수를 지정하는 매개변수입니다. \n",
    "# 히스토그램은 데이터를 구간으로 나누고 각 구간에 속하는 데이터의 개수를 나타내는 그래프입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c77b3",
   "metadata": {},
   "source": [
    "위에서부터 차례대로 그래프는 각각 실제 텍스트와 요약의 길이 분포, 실제 텍스트 샘플 길이별 개수, 요약본 샘플 길이별 개수를 나타냅니다.  \n",
    "\n",
    "**Text 그래프 분석**  \n",
    "- boxplot : Text의 경우 최소 길이가 2, 최대 길이가 1,235로 그 차이가 굉장히 크다.\n",
    "- 히스토그램(hist) : 하지만 평균 길이는 38로 시각화된 그래프로 봤을 때는 대체적으로는 100 내외의 길이를 가진다는 것을 확인할 수 있다.  \n",
    "    \n",
    "**Summary 그래프 분석**  \n",
    "- boxplot : 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧다.\n",
    "- 히스토그램(hist) : 대체적으로 10이하의 길이를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfc30f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 지정\n",
    "\n",
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75525aa4",
   "metadata": {},
   "source": [
    "**최대 길이 결정하는 방법**  \n",
    "- 각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인해보기\n",
    "- 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "beff1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 임의 지정한 최대 길이 내에 데이터의 몇 %가 해당하는지 확인하는 함수 만들기\n",
    "\n",
    "# max_len은 주어진 길이(임의로 지정한 길이)\n",
    "# nested_list는 훈련 데이터 리스트 (중첩 리스트)\n",
    "# 중첩 리스트는 리스트 안에 다른 리스트가 포함된 형태를 말한다.\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0   # max_len 이하인 샘플의 개수를 세기 위해 cnt 변수를 초기화\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89a89b",
   "metadata": {},
   "source": [
    "이 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca841d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "# 전체 샘플 중 임의 지정한 최대 길이 이하인 샘플의 비율 확인하기\n",
    "\n",
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f698744",
   "metadata": {},
   "source": [
    "각각 50과 8로 패딩을 하게 되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 망가지게 됩니다.  \n",
    "정해진 길이에 맞춰 자르는 것이 아니라, **정해진 길이보다 길면 제외하는 방법**으로 데이터를 정제해보겠습니다.  \n",
    "\n",
    "Q. Text와 Summary를 담고 있는 data 데이터프레임을 위에서 임의로 정의한 text_max_len과 summary_max_len의 길이보다 큰 샘플을 제외하는 코드를 작성하세요.   \n",
    "(힌트 : apply 함수와 lamda식을 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d601537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data.apply(lambda row: len(row['Text'].split()) <= text_max_len and len(row['Summary'].split()) <= summary_max_len, axis=1)]\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))\n",
    "\n",
    "# axis=1 로 설정하여 각 행에 대하여 함수를 적용하여, 각 행의 값들을 함수에 전달\n",
    "# data[]에서 대괄호 []는 데이터프레임에서 조건을 만족하는 행들을 선택하기 위한 인덱싱 방법으로,\n",
    "# 위의 코드는 조건을 만족하는 행들로 이루어진 새로운 데이터프레임을 생성한 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ad4b9",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈춥니다.  \n",
    "\n",
    "![SOS, EOS](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-4.png)  \n",
    "- 시작 토큰 SOS와 종료 토큰 EOS는 각각 start of a sequence와 end of a sequence를 나타냅니다.\n",
    "- https://arxiv.org/pdf/1812.02303.pdf  \n",
    "\n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가해야 합니다.  \n",
    "이번 실습에서는 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 명명하고 앞, 뒤로 추가합니다.   \n",
    "다음과 같이 변수를 설정합니다.  \n",
    "- 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input   \n",
    "- 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target\n",
    "두 개의 문장 모두 Summary 열로부터 만듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ced6a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e078c",
   "metadata": {},
   "source": [
    "앞뒤로 토큰이 잘 붙었습니다.  \n",
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b1bb464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 레이블을 각각 Numpy 타입으로 저장\n",
    "\n",
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664ec15",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 테스트 데이터를 분리하기\n",
    "\n",
    "훈련 데이터와 테스트 데이터를 분리하는 방법    \n",
    "- 분리 패키지를 사용하는 방법\n",
    "- 직접 코딩을 통해서 분리하는 방법 등 여러 가지 방법이 있음\n",
    "\n",
    "이번 실습에서는 직접 분리해봅니다.   \n",
    "우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "515a79f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61067 36023  4505 ... 21350 43731 20603]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스 만들기\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f73407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65818,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 샘플 수 shape으로 확인하기\n",
    "\n",
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c0883f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65818,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc5a79",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6733db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 시퀀스의 배열을 이용하여 잘 섞인 샘플(encoder_input, decoder_input, decoder_target) 만들기\n",
    "\n",
    "encoder_input = encoder_input[indices]   # encoder_input 배열의 행을 indices에 주어진 순서대로 재배열\n",
    "decoder_input = decoder_input[indices]   # decoder_input 배열의 행을 indices에 주어진 순서대로 재배열\n",
    "decoder_target = decoder_target[indices] # decoder_target 배열의 행을 indices에 주어진 순서대로 재배열\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb876c1",
   "metadata": {},
   "source": [
    "이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리합니다.   \n",
    "전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20010e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "# test data 크기 정하기 - 전체 데이터의 20%\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7fab2",
   "metadata": {},
   "source": [
    "이렇게 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분합니다.    \n",
    ":표시의 위치에 주의해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7209fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 각각의 train, test data로 나누기\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]   # 전체데이터의 처음부터 테스트데이터(20%) 전까지 = 80%\n",
    "decoder_input_train = decoder_input[:-n_of_val]   # 디코더입력의 처음부터 테스트데이터(20%) 전까지 = 80%\n",
    "decoder_target_train = decoder_target[:-n_of_val] # 디코더레이블의 처음부터 테스트데이터(20%) 전까지 = 80%\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]    # 전체데이터의 나머지 = 20%\n",
    "decoder_input_test = decoder_input[-n_of_val:]    # 디코더입력의 나머지 = 20%\n",
    "decoder_target_test = decoder_target[-n_of_val:]  # 디코더레이블의 나머지 = 20%\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134dcea",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터가 각각 52,655개와 13,163개로 잘 분리되었습니다!  \n",
    "\n",
    "- encoder의 input(을 80:20으로 나누기)\n",
    "    - encoder의 (훈련 데이터) 80% -> 훈련 데이터의 개수\n",
    "    - encoder의 (훈련 레이블) 20% -> 데스트 데이터의 개수\n",
    "- decoder의 input(을 80:20으로 나누기)\n",
    "    - decoder의 (테스트 데이터) 80% -> 훈련 레이블의 개수\n",
    "    - decoder의 (테스트 레이블) 20% -> 테스트 레이블의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfebc73",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리하기 - (3) 정수 인코딩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84132d",
   "metadata": {},
   "source": [
    "### 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
    "#### 단어 집합 만들기란?\n",
    "- 훈련 데이터와 테스트 데이터의 각 단어에 고유한 정수를 맵핑하는 작업 (기계가 텍스트를 숫자로 처리할 수 있도록)  \n",
    "\n",
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 합니다.  \n",
    "이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요합니다. 이 과정을 단어 집합(vocabulary) 을 만든다고 표현합니다.   \n",
    "\n",
    "훈련 데이터에 대해서 단어 집합을 만들어봅니다. 우선, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만들겠습니다.   \n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d28e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터에 대한 단어 집합 만들기 - keras의 토크나이저 사용\n",
    "\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427351fc",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다.  \n",
    "현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어 있습니다.   \n",
    "\n",
    "그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, **빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행**하려 합니다.  \n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해보겠습니다.   \n",
    "\n",
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d211859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 한 눈에 보기\n",
    "# src_tokenizer.fit_on_texts() : 입력된 데이터로부터 단어 집합 생성 \n",
    "# src_tokenizer.word_index : 생성된 단어 집합이 저장된 곳\n",
    "# src_tokenizer.word_counts.items() : 단어와 각 단어의 등장 빈도수가 저장되어있는 통계적인 정보를 얻을 수 있는 곳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6f48a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 32003\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23741\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8262\n",
      "단어 집합에서 희귀 단어의 비율: 74.18367028091116\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.386673546568334\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069303e",
   "metadata": {},
   "source": [
    "#### 통계 정보 해석\n",
    "- encoder_input_train에는 3만여 개의 단어가 있습니다.\n",
    "- 등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지합니다. \n",
    "- 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않습니다.\n",
    "- 그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. \n",
    "- 위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한해보겠습니다.\n",
    "- 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "853d4b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합의 크기 제한 (8000개)\n",
    "\n",
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da56c3b0",
   "metadata": {},
   "source": [
    "texts_to_sequences() : 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행  \n",
    "\n",
    "현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb10b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7655, 1692, 1051, 5, 714, 163, 2, 119, 62, 441, 27, 149, 193], [861, 55, 21, 610, 2, 258, 1, 227, 145, 31], [1, 11, 1076, 33, 358, 177, 877, 1, 4, 166, 20, 1606, 34, 11, 2, 7, 207]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94dbe6",
   "metadata": {},
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있습니다.  \n",
    "\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행합니다.  \n",
    "케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14cfa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_train에 대한 단어 집합 만들기 - 케라스의 토크나이저를 사용하여\n",
    "# = 훈련 데이터의 레이블 = Summary 데이터\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)   # 전체 단어 집합과 각 단어에 대한 빈도수 계산\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96916a",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다.  \n",
    "tar_tokenizer.word_counts.items()으로 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c53f5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 한 눈에 보기\n",
    "# tar_tokenizer.fit_on_texts() : 입력된 데이터(decoder_input_train)로부터 단어 집합 생성 \n",
    "# tar_tokenizer.word_index : 생성된 단어 집합이 저장된 곳\n",
    "# tar_tokenizer.word_counts.items() : 단어와 각 단어의 등장 빈도수가 저장되어있는 통계적인 정보를 얻을 수 있는 곳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e580679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10483\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8103\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2380\n",
      "단어 집합에서 희귀 단어의 비율: 77.29657540780312\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.891726603212886\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_train - 단어와 단어의 등장 빈도수 통계 정보  \n",
    "\n",
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142de0d3",
   "metadata": {},
   "source": [
    "> 등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있습니다.  \n",
    "> 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.87%밖에 되지 않습니다.  \n",
    "> 아까 했던 것과 동일하게 이 단어들은 모두 제거합니다.  \n",
    "> 어림잡아 2,000을 단어 집합의 크기로 제한합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3da9e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1455], [1, 258], [1, 21, 621], [1, 17], [1, 141]]\n",
      "target\n",
      "decoder  [[1455, 2], [258, 2], [21, 621, 2], [17, 2], [141, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)    # 단어 집합 만드는 Tokenizer 사용 - 단어 개수 2000개로 제한\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)   # 단어 집합 만들기 : decoder_input_train\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)  # 단어 집합 만들기 : decoder_target_train\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6f3b4",
   "metadata": {},
   "source": [
    "정상적으로 정수 인코딩 작업이 끝났습니다.  \n",
    "현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 넘는 숫자들은 존재하지 않습니다.  \n",
    "\n",
    "**다음 작업인 패딩 하기로 넘어가기 전에 한 가지 점검해야 할 것!**   \n",
    "- 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것 = 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있다.  \n",
    "    이 현상은 \n",
    "    - 원문(Text)의 경우 : 길이가 상대적으로 길었기 때문에 문제가 별로 없겠지만, (빈 샘플이 생기는 경우가 적겠지만)\n",
    "    - 요약문(Summary)의 경우 : 애초에 평균 길이가 4밖에 되지 않았기 때문에 이 현상이 굉장히 두드러졌을 가능성이 높을 것.    \n",
    "    => 빈 샘플이 많아지기 쉬울 것(Text에 비해). 요약문 1개 당 평균 길이가 4밖에 안되므로   \n",
    "    \n",
    "\n",
    "- 요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와서 확인하기!\n",
    "    - 여기서 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, \n",
    "    - 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않는다.\n",
    "    - 그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 것 (sos 또는 eos만 남아있으므로)\n",
    "    - 왜냐하면 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을테니\n",
    "    \n",
    "**빈 샘플의 인덱스를 변수에 담기**    \n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해봅니다.     \n",
    "이 샘플들은 모두 삭제하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02af45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1251\n",
      "삭제할 테스트 데이터의 개수 : 359\n",
      "훈련 데이터의 개수 : 51404\n",
      "훈련 레이블의 개수 : 51404\n",
      "테스트 데이터의 개수 : 12804\n",
      "테스트 레이블의 개수 : 12804\n"
     ]
    }
   ],
   "source": [
    "# 빈 샘플 삭제하기\n",
    "\n",
    "# 빈 샘플의 인덱스를 변수에 담기 - 빈 샘플인지는 decoder_input에서 확인\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "# decoder_input_train에서 빈 샘플이 없는 경우만 train data들에 남기기\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "# decoder_input_test에서 빈 샘플이 없는 경우만 test data들에 남기기\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6a325",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있습니다.   \n",
    "\n",
    "> 헷갈리는 것 정리!  \n",
    "> - 훈련 데이터&레이블 : ㅇㅇㅇ_input_train   \n",
    "    ㅇㅇㅇ이\n",
    "    - encoder이면 (훈련) 데이터\n",
    "    - decoder이면 (훈련 데이터의) 레이블\n",
    "> - 테스트 데이터&레이블 : ㅇㅇㅇ_input_test   \n",
    "    ㅇㅇㅇ이\n",
    "    - encoder이면 (테스트) 데이터\n",
    "    - decoder이면 (테스트 데이터의) 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fbc8b",
   "metadata": {},
   "source": [
    "### 패딩하기\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 합니다.  \n",
    "- 아까 정해두었던 최대 길이로 패딩 해줍니다. \n",
    "- 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "753e27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩하기\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')\n",
    "\n",
    "# padding='post' 옵션은 시퀀스의 뒷부분에 패딩을 추가하는 것을 의미합니다. 패딩된 부분은 0으로 채워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06447c",
   "metadata": {},
   "source": [
    "이제 학습에 필요한 데이터 전처리가 모두 완료되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99715167",
   "metadata": {},
   "source": [
    "## 5. 모델 설계하기\n",
    "\n",
    "### 인코더 설계\n",
    "함수형 API를 이용해서 인코더를 설계합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a66a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256   # 단기 상태\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "# Embedding(훈련 데이터의 단어 집합 크기, embedding_dim)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
    "\n",
    "\n",
    "# hidden_size: LSTM 레이어의 은닉 상태의 크기 또는 차원을 나타냅니다.\n",
    "# return_sequences=True: LSTM 레이어가 시퀀스 전체에 대한 출력을 반환하도록 지정합니다. \n",
    "# True로 설정되면 각 타임 스텝에서의 출력이 모델의 다음 레이어로 전달됩니다.\n",
    "# return_state=True: LSTM 레이어가 마지막 타임 스텝의 출력뿐만 아니라 마지막 타임 스텝의 은닉 상태도 반환하도록 지정합니다.\n",
    "# dropout=0.4: LSTM 셀의 입력에 대한 드롭아웃 비율을 나타냅니다. 모델의 과적합을 방지하기 위해 사용되는 정규화 기법 중 하나입니다.\n",
    "# recurrent_dropout=0.4: LSTM 셀의 순환 상태에 대한 드롭아웃 비율을 나타냅니다. 이는 순환 상태의 드롭아웃으로, 시간에 따른 은닉 상태의 변화를 제어합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b84cd",
   "metadata": {},
   "source": [
    "- 임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요.   \n",
    "- hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요.   \n",
    "    - 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 돼요. \n",
    "    - 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.\n",
    "\n",
    "- 인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요.   \n",
    "    - hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. \n",
    "    - 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "- 또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용할 수 있어요. \n",
    "    - 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법이에요.\n",
    "\n",
    "- 반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이에요. \n",
    "    - 즉 time step의 입력을 랜덤으로 생략해 주는 거죠. \n",
    "    - recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 해요.\n",
    "\n",
    "아래 그림은 일반적인 dropout과, dropout과 recurrent dropout을 동시에 사용한 것을 시각적으로 표현한 것입니다.   \n",
    "색이 있는 화살표는 dropout을 나타낸 것이에요. (색이 다른 것은 다른 dropout mask를 사용했다는 표시인데, 지금은 그냥 넘어가셔도 됩니다.)   \n",
    "코드를 수정해서 LSTM에 dropout과 recurrent dropout을 모두 사용할 수 있습니다. 그렇게 되면 오른쪽 그림과 같은 형태가 되겠군요.   \n",
    "참고로 dropout과 recurrent dropout을 모두 사용한 것을 Variational Dropout이라고도 해요.\n",
    "\n",
    "![dropout(왼쪽)과 dropout + recurrent dropout(오른쪽)](https://d3s0tskafalll9.cloudfront.net/media/images/seukeurinsyas_2021-10-28_17-19-50.max-800x600.png)\n",
    "[이미지 참조 논문](https://arxiv.org/pdf/1512.05287.pdf)\n",
    "\n",
    "> 참고로 recurrent dropout을 사용하면 아래와 같은 경고문이 뜹니다.  \n",
    "\n",
    "> WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU  \n",
    "\n",
    "> recurrent dropout을 사용할 시 cuDNN을 사용할 수 없어서 recurrent dropout을 사용하지 않을 때보다 학습 시간이 오래 걸립니다.  \n",
    "\n",
    "recurrent dropout에 대한 자세한 내용은 아래의 논문을 참고하세요.\n",
    "[Recurrent Dropout without Memory Loss](https://arxiv.org/pdf/1603.05118v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57505a98",
   "metadata": {},
   "source": [
    "### 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "327db639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))   # 디코더의 입력 시퀀스를 나타내는 텐서\n",
    "\n",
    "# 디코더의 임베딩 층 \n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)   # 목표 언어의 어휘 크기와 임베딩 차원을 가지고 있다.\n",
    "dec_emb = dec_emb_layer(decoder_inputs)   # 디코더의 입력 시퀀스에 대한 임베딩을 수행\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# decoder_lstm : \n",
    "# 디코더의 LSTM 레이어. 이 LSTM 레이어는 인코더의 최종 은닉 상태와 셀 상태를 초기 상태로 받아들입니다. \n",
    "# 또한, return_sequences=True로 설정되어 시퀀스 전체에 대한 출력을 반환합니다.\n",
    "# decoder_outputs: \n",
    "# 디코더 LSTM 레이어의 출력입니다. 이는 디코더의 각 타임 스텝에서의 출력으로 이루어진 시퀀스입니다. \n",
    "# 나중에 소프트맥스 레이어를 통과하여 최종적인 예측을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2000ece",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일합니다.  \n",
    "하지만 **LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야** 해요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6015d9d",
   "metadata": {},
   "source": [
    "### 디코더의 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a61dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 128)      1024000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 50, 256), (N 394240      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 50, 256), (N 525312      lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 128)    256000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 50, 256), (N 525312      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 256),  394240      embedding_4[0][0]                \n",
      "                                                                 lstm_9[0][1]                     \n",
      "                                                                 lstm_9[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 2000)   514000      lstm_10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313de77",
   "metadata": {},
   "source": [
    "**인코딩 부분:**\n",
    "\n",
    "input_4 (인코더의 입력 시퀀스) → embedding_3 (인코더의 임베딩 층)    \n",
    "→ lstm_7 (인코더의 LSTM 레이어) → lstm_8 (인코더의 LSTM 레이어) → lstm_9 (인코더의 LSTM 레이어)\n",
    "따라서, lstm_9 까지가 인코딩 부분입니다. 이 레이어까지가 입력 시퀀스를 압축하고 중요한 정보를 추출하는 역할을 합니다.\n",
    "\n",
    "**디코딩 부분:**\n",
    "\n",
    "input_5 (디코더의 입력 시퀀스) → embedding_4 (디코더의 임베딩 층) → lstm_10 (디코더의 LSTM 레이어) → dense (디코더의 출력 층)\n",
    "디코더는 인코더의 정보를 이용하여 출력 시퀀스를 생성합니다. 이 부분은 lstm_10부터 dense까지로 이루어져 있습니다.\n",
    "\n",
    "요약하면, 인코딩은 input_4에서 lstm_9까지, 디코딩은 input_5에서 dense까지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7948f",
   "metadata": {},
   "source": [
    "> 디코더의 입력 decoder_inputs의 shape가 (None, 50)로 나오는 이유는 텐서플로(TensorFlow)의 기본 동작과 관련이 있습니다.   \n",
    "여기에서 None은 가변 길이 시퀀스를 나타내며, 모델을 정의할 때 시퀀스의 길이를 정해주지 않았기 때문에 None으로 표현됩니다.   \n",
    "이는 훈련할 때 다양한 길이의 시퀀스를 모델에 입력으로 사용할 수 있음을 의미합니다.   \n",
    "실제로는 훈련 데이터의 시퀀스 길이에 따라 이 값이 동적으로 결정됩니다.  \n",
    "\n",
    "> 50은 디코더의 입력 시퀀스의 길이를 나타내며 훈련 데이터의 특성에 따라 결정됩니다.  \n",
    "해당 모델에서 디코더에 입력되는 시퀀스의 최대 길이를 50으로 가정했다는 의미이며,  \n",
    "적절한 값은 실험을 통해 작업자가 찾아가야 합니다.  \n",
    "\n",
    "> embedding_1 레이어의 출력 shape인 (None, None, 128)  \n",
    "> - 첫 번째 None: 배치 크기(batch size)에 해당하는 차원입니다.   \n",
    "훈련할 때 모델은 배치 단위로 데이터를 처리하므로, 이 차원은 배치 크기에 따라 동적으로 변합니다.\n",
    "> - 두 번째 None: 디코더의 입력 시퀀스 길이에 해당하는 차원입니다. 디코더의 입력은 가변 길이이기 때문에, 실제 데이터의 길이에 따라 동적으로 결정됩니다. \n",
    "> - 128: 임베딩 차원입니다. 이는 각 단어를 나타내는 벡터의 차원 수를 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1baeb",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 합니다.  \n",
    "그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용합니다.  \n",
    "\n",
    "지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq 입니다.  \n",
    "그런데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있어요! 바로 어텐션 메커니즘입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02e53c",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 뜻입니다.   \n",
    "어텐션 함수를 설계해보는 것은 다음 기회로 미루기로 하고,   \n",
    "여기서는 TensorFlow에 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 확인해봅니다.  \n",
    "참고로 여기서 사용하는 어텐션 함수는 Bahdanau 스타일의 어텐션입니다. (이 어텐션에 대한 자세한 설명은 텐서플로우 홈페이지를 참고)  \n",
    "\n",
    "아래와 같이 어텐션 층을 만들고, 위에서 설계한 디코더의 출력층을 수정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "960afc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 128)      1024000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 50, 256), (N 394240      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 50, 256), (N 525312      lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 128)    256000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 50, 256), (N 525312      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 256),  394240      embedding_4[0][0]                \n",
      "                                                                 lstm_9[0][1]                     \n",
      "                                                                 lstm_9[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_10[0][0]                    \n",
      "                                                                 lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_10[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,145,360\n",
      "Trainable params: 4,145,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e54b9",
   "metadata": {},
   "source": [
    "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고,   \n",
    "어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동하고 있어요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577f070",
   "metadata": {},
   "source": [
    "[seq2seq와 어텐션 메커니즘의 작동 방식](https://glee1228.tistory.com/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1207cd5",
   "metadata": {},
   "source": [
    "## 6. 모델 훈련하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be4ce312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 37s 140ms/step - loss: 2.7026 - val_loss: 2.4242\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 29s 144ms/step - loss: 2.3704 - val_loss: 2.2773\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 28s 142ms/step - loss: 2.2182 - val_loss: 2.1529\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 28s 142ms/step - loss: 2.1051 - val_loss: 2.0734\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 2.0245 - val_loss: 2.0236\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.9615 - val_loss: 1.9814\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.9074 - val_loss: 1.9565\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.8603 - val_loss: 1.9263\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.8200 - val_loss: 1.9064\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.7826 - val_loss: 1.8944\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.7480 - val_loss: 1.8833\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 29s 143ms/step - loss: 1.7163 - val_loss: 1.8777\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.6877 - val_loss: 1.8713\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.6590 - val_loss: 1.8638\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 28s 142ms/step - loss: 1.6326 - val_loss: 1.8623\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 29s 142ms/step - loss: 1.6073 - val_loss: 1.8623\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 22s 111ms/step - loss: 1.5816 - val_loss: 1.8642\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f152c1",
   "metadata": {},
   "source": [
    "'조기 종료'를 뜻하는 EarlyStopping은 특정 조건이 충족되면 훈련을 멈추는 역할을 합니다.  \n",
    "\n",
    "#### es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)  \n",
    "\n",
    "위 코드에서는 val_loss(검증 데이터의 손실)을 관찰하다가,   \n",
    "검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정돼 있습니다.  \n",
    "EarlyStopping이 작동한다면 epochs가 아무리 크게 설정되어 있어도 모델 훈련을 최적점에서 멈출 수 있습니다.\n",
    "\n",
    "[early stopping 공식문서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)  \n",
    "\n",
    "- min_delta : 개선된 것으로 간주하기 위한 최소한의 변화량. min_delta가 0.01이면 정확도가 그 이상 개선되어야 개선된 것으로 판단.\n",
    "- baseline : 모델이 달성해야하는 최소한의 기준값을 선정합니다.  \n",
    "patience 이내에 모델이 baseline보다 개선됨이 보이지 않으면 Training을 중단시킵니다.\n",
    "- restore_best_weights : \n",
    "    - True라면 training이 끝난 후, model의 weight를 monitor하고 있던 값이 가장 좋았을 때의 weight로 복원합니다.\n",
    "    - False라면, 마지막 training이 끝난 후의 weight로 놔둡니다.\n",
    "- start_from_epoch : 조기 종료를 적용할 에포크(epoch)를 지정합니다.   \n",
    "즉, 이 매개변수를 사용하면 일정한 에포크 이후부터 얼리스탑핑을 적용할 수 있습니다.  \n",
    "start_from_epoch=5로 설정하면 훈련 시작 후 5번째 에포크 이후부터 얼리스탑핑이 작동합니다.  \n",
    "개선 모니터링을 시작하기 전에 기다려야 하는 에포크 수입니다.   \n",
    "이를 통해 개선이 예상되지 않고 훈련이 중단되지 않는 준비 기간이 허용됩니다. 기본값은 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80300da9",
   "metadata": {},
   "source": [
    "**Q. Early Stopping을 사용할 경우 조심해야 하는 경우는?**  \n",
    "patience가 0이 아닌 경우에는 훈련이 종료되었을 때 성능이 최고인 상황이 아닐 수 있습니다.   \n",
    "예를 들어 patience가 3인 경우, 15 epoch에서 loss가 감소하다가 16 epoch부터 loss가 증가한다면 18 epoch 때 모델을 저장하고 학습을 종료합니다.   \n",
    "그래서 학습 중에 모델을 저장하는 callback 함수를 같이 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbca91cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cacd06",
   "metadata": {},
   "source": [
    "## 7. 인퍼런스 모델 구현하기\n",
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비해 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b6e1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# [테스트 단계] '정수 인덱스 행렬 -> 실제 데이터로 복원' 을 위한 사전 준비\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04186db",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 합니다.  \n",
    "- 훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로,   \n",
    "인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.\n",
    "\n",
    "- 그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에  \n",
    "부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다.\n",
    "\n",
    "### 인퍼런스 단계의 인코더 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8907403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "# 이 모델은 훈련된 인코더의 일부로, 디코더의 초개 상태를 얻기 위해 사용됩니다.\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서 - 디코더의 초기 상태를 받기 위한 입력 텐서를 생성 -> 추론 단계에서 디코더의 초기 상태 설정을 위해 사용됨.\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "# 디코더의 임베딩 적용 - 디코더의 입력 시퀀스에 대한 임베딩을 적용\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "\n",
    "# 디코더의 LSTM 실행\n",
    "# 추론 단계에서 사용되어 디코더를 한 시점씩 진행하며 다음 단어를 예측\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f24509",
   "metadata": {},
   "source": [
    "> 이렇게 구성된 모델은 훈련된 Seq2Seq 모델에서 인코더 부분과 일부 디코더 부분을 추출하여 훈련과정에서 사용한 모델과는 독립적으로 동작할 수 있습니다.\n",
    "\n",
    "### 어텐션 메커니즘을 사용하는 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6711ba88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 메커니즘을 사용하는 출력층 설계\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))    # 인코더의 출력과 어텐션을 계산하기 위한 입력\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)    # 다음 단어의 확률 분포를 계산\n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')\n",
    "\n",
    "\n",
    "# attn_out_inf : 어텐션의 결과로,\n",
    "# 디코더의 출력 (decoder_outputs2)과 인코더의 출력 (decoder_hidden_state_input)을 입력으로 받아 어텐션을 계산\n",
    "\n",
    "# decoder_model : 디코더의 동작을 정의하는 모델로, \n",
    "# 입력으로 디코더의 초기 상태와 어텐션을 계산한 결과를 받고, 출력으로 다음 단어의 확률 분포와 업데이트된 상태를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a985eab",
   "metadata": {},
   "source": [
    "이렇게 구성된 디코더 모델은 훈련된 Seq2Seq 모델에서 디코더 부분을 추출하여, 새로운 입력에 대해 시퀀스를 생성하는 데 사용됩니다.  \n",
    "\n",
    "### 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93af34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    # input_seq에 대한 인코더의 출력 (e_out) 및 마지막 은닉 상태 (e_h) 및 마지막 셀 상태 (e_c)를 반환\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    # 디코더 입력 시퀀스를 초기화하고, <SOS> (시작 토큰)에 해당하는 인덱스로 설정\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    # stop_condition이 True가 될 때까지 루프 반복 : <EOS> (종료 토큰)에 도달하거나 최대 요약 길이에 도달할 때까지 계속 반복\n",
    "    while not stop_condition: \n",
    "\n",
    "        # 디코더 모델에 대한 예측: decoder_model을 사용하여 디코더의 출력 토큰, 새로운 은닉 상태 (h), 새로운 셀 상태 (c)를 얻습니다.\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        # 샘플링된 토큰 확인 및 문장 구성: 디코더의 출력 중 가장 확률이 높은 토큰을 샘플링합니다.\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        # 디코딩 결과 및 중단 조건 확인: 디코딩된 토큰을 결과 문장에 추가하고, <EOS>에 도달하거나 최대 길이에 도달하면 디코딩을 중단합니다.\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e0a8d",
   "metadata": {},
   "source": [
    "Q. 정답 문장이 없는 추론(inference) 단계에서는 왜 모델 설계를 별도로 해주어야 하나요?  \n",
    "A. 생성해야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e25ed",
   "metadata": {},
   "source": [
    "## 8. 모델 테스트하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d23e94",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편합니다.\n",
    "주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어봅니다.   \n",
    "함수를 만들 때,   \n",
    "- Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 \n",
    "- Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만듭니다.\n",
    "\n",
    "Q. seq2text 함수처럼 요약문의 정수 시퀀스를 텍스트로 변환하는 seq2summary 함수 코드를 작성하세요.\n",
    "(힌트 : 요약문에는 sostoken과 eostoken을 고려해야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1306a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if i == tar_word_to_index['eostoken']:\n",
    "            break\n",
    "        if i != 0 and i != tar_word_to_index['sostoken']:\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')\n",
    "\n",
    "\n",
    "# temp : 문자열을 저장하는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7aad94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : want great granola look live none stores carry mail order granola get something good \n",
      "실제 요약 : yummy \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : ordered product vacation delivered quickly exactly expected continue order item \n",
      "실제 요약 : good to the last drop \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : dogs chewed apart matter minutes eating small parts dogs powerful chewers \n",
      "실제 요약 : nylabone durable dental dinosaur \n",
      "예측 요약 :  not for me\n",
      "\n",
      "\n",
      "원문 : bought hearing best reading good reviews previously tried wilton markers horrible excited try cake pops stopped working cleaned paper towel recommended packaging markers worked fine soon tried write candy nothing would happen understand work seem work great others \n",
      "실제 요약 : disappointed \n",
      "예측 요약 :  not for me\n",
      "\n",
      "\n",
      "원문 : maxwell house coffee great aroma excellent taste less expensive local store delivered front door shipping cost \n",
      "실제 요약 : great coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : purchased one one day really enjoyed found amazon ordered flavor favorite coconut bars taste great like protein natural bars tried past would recommend bars quick snack work even breakfast \n",
      "실제 요약 : great all natural bar \n",
      "예측 요약 :  great tasting snack\n",
      "\n",
      "\n",
      "원문 : used problems digestion lot gas since started taking type honey every meal things got lot better love \n",
      "실제 요약 : simply amazing \n",
      "예측 요약 :  great for\n",
      "\n",
      "\n",
      "원문 : delicious coffee love cups price right amazon great cup coffee anytime day purchase \n",
      "실제 요약 : yum \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : tried one shot bed really helped fall asleep works better prescription sleep medicine probably better \n",
      "실제 요약 : worth every penny \n",
      "예측 요약 :  works for me\n",
      "\n",
      "\n",
      "원문 : bought parents laws christmas steaks arrived time everyone moon gift next year gave stars price pretty sure kobe beef maybe wrong better kobe price point \n",
      "실제 요약 : happy \n",
      "예측 요약 :  not as good as expected\n",
      "\n",
      "\n",
      "원문 : kitty loves knows keep funny wants get top basket begins bags \n",
      "실제 요약 : kitty love \n",
      "예측 요약 :  cat loves it\n",
      "\n",
      "\n",
      "원문 : compared health food store amazon price far better value buy suggest keep sealed jar put open snack dish absorbed awful lost crunchiness otherwise love snack \n",
      "실제 요약 : wheat nuts \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : pleased purchase yoo hoo purchasing future thank \n",
      "실제 요약 : excellant \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : high hopes delicious disappointed flavor texture felt slimy tongue flavor even close tasting like ranch dressing ever threw away \n",
      "실제 요약 : in the garbage it went \n",
      "예측 요약 :  not that\n",
      "\n",
      "\n",
      "원문 : best coffee ever available great product speedy delivery affordable price return every time need highly recommend \n",
      "실제 요약 : cafe beans from \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : boston baked beans candy coated peanuts favorite candy small boxes delicious beans packaged larger box cute display punch stores easy access beans small boxes make easy take pack whenever get craving like happens lot great value quality purchase \n",
      "실제 요약 : delicious candy packaged super \n",
      "예측 요약 :  great value\n",
      "\n",
      "\n",
      "원문 : good tasty authentic flavor ordered last minute christmas knowing going arrive time arrived house christmas eve \n",
      "실제 요약 : good \n",
      "예측 요약 :  great tasting\n",
      "\n",
      "\n",
      "원문 : love product particular size big like thought might add anything everything eat alone toothpicks late night snack alternative mash sometimes homemade fried beans farts cannot go wrong product \n",
      "실제 요약 : awesome ready go product no \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : taste found almost cheese flavor also odd background flavor taste course personal view probably eating habits experience may vary record think cheetos taste like cheese either \n",
      "실제 요약 : did not like these at all \n",
      "예측 요약 :  good but not great\n",
      "\n",
      "\n",
      "원문 : taylor excellent tea old roommate mine england several years ago looked back highly recommend \n",
      "실제 요약 : yum love this tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : originally bought year old mind yummy eat great healthy snack travels well \n",
      "실제 요약 : amazing and addictive \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : using product years pretty well great add cocktails great way make water interesting without adding significant amounts sugar \n",
      "실제 요약 : tried and true \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : bought product deter bulbs planted garden learned blog care red pepper stay away think big provide alternate snacks good price relatively large quantity plastic container top perfect keep handy supplies eaten smells quite strong think good stuff \n",
      "실제 요약 : bought to in \n",
      "예측 요약 :  good quality\n",
      "\n",
      "\n",
      "원문 : first time bought tea amazon used get directly revolution tea know made difference change tea used wife favorite tea metallic smell aftertaste much less pomegranate flavor strong almost cheap generic green tea flavor really disappointing especially since stuck six boxes \n",
      "실제 요약 : tastes different and much worse than before \n",
      "예측 요약 :  very disappointed\n",
      "\n",
      "\n",
      "원문 : absolutely love product live caribbean going costco constantly get product going problem thank amazon alternative method satisfying desire delicious fruits \n",
      "실제 요약 : always my favourite delicious \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : mild extremely smooth chocolaty start slightly fruity middle finish smooth smooth would like lack richness looking really great casual drink enjoy food \n",
      "실제 요약 : no idea why it is so cheap \n",
      "예측 요약 :  great flavor\n",
      "\n",
      "\n",
      "원문 : got today put one freezer could drink asap omg little leary wonderful people like little pieces drink love amazed great taste many calories may add little vitamin water normally drink enjoying bottle refreshing \n",
      "실제 요약 : very pleasantly surprised \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n",
      "원문 : received packages boxes double inside original box torn cans dented quality inside fine appearance product bad \n",
      "실제 요약 : the packages are terrible \n",
      "예측 요약 :  expired\n",
      "\n",
      "\n",
      "원문 : love coffee since cannot drink caffeine one coffee world wonderful full flavor prices gotten way hand draw back find trying coffees around world date none flavor illy caffe decaffeinated \n",
      "실제 요약 : illy decaf whole bean coffee \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : arrived great condition gift year old son already lots new baby green leaves excellant product great price \n",
      "실제 요약 : great product \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : dogs preferred years one need small size local store changed medium awhile back put request small since done looked found actually little less expensive well complaint boxes taped together hoped able share boxes looked damaged got tape really possible great shipping great product poor packaging \n",
      "실제 요약 : packaged for product fine \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love blend chicken caesar salad used start thinking hours lunch serve chicken hot drizzled fresh lime juice awesome must times \n",
      "실제 요약 : chicken salad \n",
      "예측 요약 :  great flavor\n",
      "\n",
      "\n",
      "원문 : noodles fabulous even kids love gluten intolerant love noodles back life wonderful flavor texture amazing \n",
      "실제 요약 : love the can eat noodles again \n",
      "예측 요약 :  great for pasta\n",
      "\n",
      "\n",
      "원문 : company makes food highest natural ingredients worried cat would like gobbled instantly cat sensitive stomach food easy digest stomach highly recommend \n",
      "실제 요약 : healthy and tasty \n",
      "예측 요약 :  great food\n",
      "\n",
      "\n",
      "원문 : ordered mahogany caribou coffee cups adore recommend product like bold coffe smooth taste \n",
      "실제 요약 : love caribou \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : crazy chicken broccoli skillets dinner kit mostly tiny amount broccoli added package frozen broccoli improved things considerably wish bit less sodium whole grain pasta bad way velveeta included improve overall dinner \n",
      "실제 요약 : needs more broccoli \n",
      "예측 요약 :  good but not great\n",
      "\n",
      "\n",
      "원문 : bought coffee jamaica liked enjoyed prefer several coffees local shops price think may worth lb certainly prices \n",
      "실제 요약 : good coffee but not great \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : product wonderful drizzle pizza mediocre mere moments \n",
      "실제 요약 : very nice \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : china nowhere good italy spend extra money get italy \n",
      "실제 요약 : not the best \n",
      "예측 요약 :  not for me\n",
      "\n",
      "\n",
      "원문 : hesitant buying something online could get local grocery store however ability read reviews kinds sugar products helped vastly decision making others considering buying pack highly recommend whether work drink ton coffee like buying large quantity makes sense sugar also perfect complement coffee type bold mild \n",
      "실제 요약 : great sugar \n",
      "예측 요약 :  excellent product\n",
      "\n",
      "\n",
      "원문 : product awesome love taste peanut butter love fat calories put tablespoon powder chocolate vanilla protein shake sometimes nice peanut buttery twist drawback expense actually purchase item linda diet website directly \n",
      "실제 요약 : delicious but cheaper elsewhere \n",
      "예측 요약 :  great tasting\n",
      "\n",
      "\n",
      "원문 : pet first introduced us bites year old picky eater really gets excited time nightly treat bites finicky eater try piece food probably happier dog \n",
      "실제 요약 : treat your best friend with the best \n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : product delicious especially rice dream even big fan blueberries anymore love cereal end story \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  great rice\n",
      "\n",
      "\n",
      "원문 : disappointed went picture description read reviews someone else stated creamer partially hydrogenated oil want stuff wanted looks buy even taste close stuff \n",
      "실제 요약 : not the same as the can \n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : product claims perfect fix someone needs little extra energy product taste good well im sorry say product bitter worth money please dont money amazon allow returns product \n",
      "실제 요약 : nasty and bitter \n",
      "예측 요약 :  good product bad price\n",
      "\n",
      "\n",
      "원문 : always keep jar around house especially winter months even feel slightest hint sore throat take spoonfuls honey goes right work great general health really rocks sore throats throat highly recommend trying honey really like son stuff flavor color definitely one highest quality honeys available \n",
      "실제 요약 : must for cold season \n",
      "예측 요약 :  best ever\n",
      "\n",
      "\n",
      "원문 : really enjoyed drink lover orange juice type drinks eager try drink perfect combination sweet fruity tangerine believe helps give extra lift sweet taste trying cut back pop highly recommend drink even refreshing treat \n",
      "실제 요약 : sweet and refreshing \n",
      "예측 요약 :  great tasting drink\n",
      "\n",
      "\n",
      "원문 : fan chocolate could miss opportunity taste test newman organics dark chocolate probably drawback going share wife chocolate strong aroma open package taste excellent chocolate breaks nicely crumble waxy great feel mouth creamy good taste chocolate overwhelm taste buds little disappointed finish long lasting flavor chocolate perhaps one drawback eating chocolate \n",
      "실제 요약 : goodness \n",
      "예측 요약 :  chocolate\n",
      "\n",
      "\n",
      "원문 : never problem amazon ordered product twice times bars almost white chocolate old dry totally disgusting buy trader joe great amazon stay away refunded times apparently still fixed problem people saying thing going amazon \n",
      "실제 요약 : old dry disgusting when bought from amazon \n",
      "예측 요약 :  disappointed\n",
      "\n",
      "\n",
      "원문 : cannot seem find little rolls life savers around anymore stores carry rolls carry one two flavors wintergreen good spearmint absolute favorite candy came fresh unbroken easiest way keep life saver supply \n",
      "실제 요약 : best flavor \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교하기\n",
    "\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c2fe2",
   "metadata": {},
   "source": [
    "많은 결과가 출력이 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보입니다.  \n",
    "심지어 일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하기도 하고 있어요. 워드 임베딩과 RNN의 콜라보로 이뤄낸 신기한 성과네요!\n",
    "\n",
    "물론 슬프게도 그다지 좋지 않은 요약의 예도 꽤나 보이기도 합니다.  \n",
    "성능을 개선하기 위해서는   \n",
    "- seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법도 있고,   \n",
    "- 빔 서치(beam search), \n",
    "- 사전 훈련된 워드 임베딩(pre-trained word embedding), \n",
    "- 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)    \n",
    "\n",
    "와 같은 여러 개선 방안들이 존재합니다. 이런 방안들에 대해서도 향후 살펴보게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84d39d",
   "metadata": {},
   "source": [
    "## 9. 추출적 요약 해보기\n",
    "앞서 seq2seq를 통해서 추상적 요약을 진행해봤습니다.  \n",
    "그런데 텍스트 요약에는 추상적 요약 외에도 이미 본문에 존재하는 단어구, 문장을 뽑아서 요약으로 삼는 추출적 요약 방법도 있었습니다.  \n",
    "\n",
    "Q. 앞에서 seq2seq 모델을 사용하여 추상적 요약을 했습니다. 그렇다면 추출적 요약은 무엇일까요?   \n",
    "A. 추출적 요약은 원문에서 중요한 핵심 문장 또는 단어를 뽑아 구성된 요약문을 만드는 방식입니다.   \n",
    "그래서 생성된 문장이나 단어는 원문에 포함되어 있기 때문에, 단점으로 언어 표현 능력이 제한되어 생성된 문장이 매끄럽지 않을 수 있습니다.   \n",
    "대표적인 알고리즘으로는 TextRank가 있습니다.  \n",
    "\n",
    "**패키지 Summa에서는 추출적 요약을 위한 모듈인 summarize를 제공**하고 있어 아주 간단하게 실습을 해볼 수 있습니다.  \n",
    "영화 매트릭스 시놉시스를 요약해보면서 summarize 사용법을 익혀보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5223604",
   "metadata": {},
   "source": [
    "### 패키지 설치\n",
    "클라우드의 경우 이미 summa 가 설치돼있습니다. 확인해보고 싶다면 아래 명령어를 Cloud Shell에서 실행해봅니다.  \n",
    "$ pip list | grep summa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1862b5",
   "metadata": {},
   "source": [
    "### 데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ac82edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data download\n",
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1ef03c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매트릭스 시놉시스를 다운로드\n",
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e5550",
   "metadata": {},
   "source": [
    "text에는 매트릭스 시놉시스가 문자열로 저장돼 있습니다. 출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d61636ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "# 시놉시스 일부를 출력해보고, 잘 저장되었는지 확인하기\n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed33813",
   "metadata": {},
   "source": [
    "### summarize 사용하기\n",
    "**Summa의 summarize()의 인자로 사용되는 값들**에 대해서 알아봅니다.  \n",
    "\n",
    "- text (str) : 요약할 테스트.  \n",
    "- ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값  \n",
    "- words (int or None, optional) – 출력에 포함할 단어 수.  \n",
    "만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.  \n",
    "- split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환  \n",
    "\n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행합니다.   \n",
    "그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있습니다.  \n",
    "비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여봅니다. 원문의 0.005%만을 출력하도록 설정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee97ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "# Summary 출력하기\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbfbc361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "# 리스트로 출력 결과를 받기 - split 인자의 값을 True로 설정\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0e91eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "# 단어의 수로 요약문의 크기를 조절하기 - 단어를 50개만 선택하도록 해보기\n",
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6c394",
   "metadata": {},
   "source": [
    "---\n",
    "## 회고\n",
    "### KEEP\n",
    "- 헷갈리는 개념을 중간 중간 정리하였다.\n",
    "- model.summary() 결과를 해석하기 위해 자료를 찾아보며 이해하려고 노력했다.\n",
    "\n",
    "### PROBLEM\n",
    "- 모델 구현 부분부터는 흐름과 구조가 그려지지 않아 코드를 이해하기 어려웠다.\n",
    "\n",
    "### TRY\n",
    "- 기본 개념과 모델 구현을 이해하기 위한 자료 찾아보기\n",
    "- 전체적인 흐름, 단계 위주로 여러 번 반복해서 보며 눈에 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a270c0",
   "metadata": {},
   "source": [
    "---\n",
    "## Reference\n",
    "- [판다스 열 삭제](https://docs.kanaries.net/ko/topics/Python/dataframe-drop-column)\n",
    "- [apply, lambda 함수](https://zephyrus1111.tistory.com/90)\n",
    "- [LSTM 아마존 리뷰 감성 분석 - torch](https://blog.naver.com/songblue61/221853600720)\n",
    "- [seq2seq와 어텐션 메커니즘의 작동방식](https://glee1228.tistory.com/3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
